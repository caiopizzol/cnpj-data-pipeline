# üáßüá∑ CNPJ Data Pipeline

Um script modular e configur√°vel para processar arquivos CNPJ da Receita Federal do Brasil. Processamento inteligente de 63+ milh√µes de empresas com suporte a m√∫ltiplos bancos de dados.

## Caracter√≠sticas Principais

- **Arquitetura Modular**: Separa√ß√£o clara de responsabilidades com camada de abstra√ß√£o de banco de dados
- **Multi-Banco**: PostgreSQL totalmente suportado, com placeholders para MySQL, BigQuery e SQLite
- **Processamento Inteligente**: Adapta√ß√£o autom√°tica da estrat√©gia baseada em recursos dispon√≠veis
- **Downloads Paralelos**: Estrat√©gia configur√°vel para otimizar velocidade de download
- **Processamento Incremental**: Rastreamento de arquivos processados para evitar duplica√ß√µes
- **Performance Otimizada**: Opera√ß√µes bulk eficientes com tratamento de conflitos
- **Configura√ß√£o Simples**: Setup interativo + vari√°veis de ambiente

## In√≠cio R√°pido

### Op√ß√£o 1: Setup Interativo (Recomendado)

```bash
# Clone o reposit√≥rio
git clone https://github.com/cnpj-chat/cnpj-data-pipeline
cd cnpj-data-pipeline

# Execute o assistente de configura√ß√£o
python setup.py
```

O assistente ir√°:
- Detectar recursos do sistema
- Configurar conex√£o com banco de dados
- Instalar depend√™ncias necess√°rias
- Criar configura√ß√£o otimizada

### Op√ß√£o 2: Configura√ß√£o Manual

```bash
# Instalar depend√™ncias
pip install -r requirements.txt

# Configurar ambiente
cp env.example .env
# Editar .env com suas configura√ß√µes

# Executar
python main.py
```

### Docker

```bash
# PostgreSQL (padr√£o)
docker-compose --profile postgres up --build

# Com configura√ß√µes customizadas
DATABASE_BACKEND=postgresql BATCH_SIZE=100000 docker-compose --profile postgres up

# Com filtros de dados
docker-compose run --rm pipeline --filter-uf SP --filter-cnae 62
```

## Filtragem de Dados

Processe apenas os dados que voc√™ precisa com filtros via linha de comando:

```bash
# Filtrar por estado (UF)
python main.py --filter-uf SP
python main.py --filter-uf SP,RJ,MG

# Filtrar por atividade econ√¥mica (CNAE)
python main.py --filter-cnae 62
python main.py --filter-cnae 62,47

# Filtrar por porte da empresa
python main.py --filter-porte 1,3  # ME e EPP

# Combinar filtros
python main.py --filter-uf SP --filter-cnae 62 --filter-porte 1

# Listar filtros dispon√≠veis
python main.py --list-filters
```

### Filtros Dispon√≠veis

| Filtro | Descri√ß√£o | Exemplo |
|--------|-----------|---------|
| `--filter-uf` | Estados brasileiros | `SP,RJ,MG` |
| `--filter-cnae` | C√≥digos de atividade (prefixo) | `62,47` |
| `--filter-porte` | Porte: 1=ME, 3=EPP, 5=Demais | `1,3` |

## Configura√ß√£o

### Sele√ß√£o de Backend

```bash
# PostgreSQL (padr√£o e recomendado)
DATABASE_BACKEND=postgresql

# Suporte futuro
# DATABASE_BACKEND=mysql
# DATABASE_BACKEND=bigquery
# DATABASE_BACKEND=sqlite
```

### Estrat√©gias de Processamento

O sistema detecta automaticamente a estrat√©gia ideal:

| Mem√≥ria | Estrat√©gia | Descri√ß√£o |
|---------|------------|-----------|
| <8GB | `memory_constrained` | Processamento em chunks pequenos |
| 8-32GB | `high_memory` | Batches maiores, cache otimizado |
| >32GB | `distributed` | Processamento paralelo m√°ximo |

### Vari√°veis de Configura√ß√£o

| Vari√°vel | Padr√£o | Descri√ß√£o |
|----------|---------|-----------|
| `BATCH_SIZE` | `50000` | Tamanho do lote para opera√ß√µes |
| `MAX_MEMORY_PERCENT` | `80` | Uso m√°ximo de mem√≥ria |
| `TEMP_DIR` | `./temp` | Diret√≥rio tempor√°rio |
| `DB_HOST` | `localhost` | Host PostgreSQL |
| `DB_PORT` | `5432` | Porta PostgreSQL |
| `DB_NAME` | `cnpj` | Nome do banco |

### Otimiza√ß√£o de Performance

| Vari√°vel | Padr√£o | Descri√ß√£o |
|----------|---------|-----------|
| `DOWNLOAD_STRATEGY` | `sequential` | `sequential` ou `parallel` |
| `DOWNLOAD_WORKERS` | `4` | N√∫mero de downloads paralelos |
| `KEEP_DOWNLOADED_FILES` | `false` | Manter arquivos para re-execu√ß√µes |

## Deployment

Este √© um job batch que processa dados CNPJ e finaliza. A Receita Federal atualiza os dados mensalmente, ent√£o agende a execu√ß√£o mensal.

### Execu√ß√£o Manual

```bash
# Executar uma vez
docker-compose up

# Com downloads paralelos
DOWNLOAD_STRATEGY=parallel DOWNLOAD_WORKERS=3 docker-compose up

# Manter arquivos para re-execu√ß√µes (economiza bandwidth)
KEEP_DOWNLOADED_FILES=true docker-compose up

# Ou sem Docker
python main.py

# Com filtros
python main.py --filter-uf SP --filter-cnae 62
```

### Execu√ß√£o Agendada (Mensal)

**Linux/Mac (cron):**
```bash
# Executar no dia 5 de cada m√™s √†s 2h da manh√£
crontab -e
# Adicionar:
0 2 5 * * cd /caminho/para/cnpj-data-pipeline && docker-compose up >> /var/log/cnpj-pipeline.log 2>&1
```

**Windows (Task Scheduler):**
- Criar tarefa agendada mensal
- Comando: `docker-compose up`

**Kubernetes:**
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cnpj-pipeline
spec:
  schedule: "0 2 5 * *"  # Dia 5 √†s 2h
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: cnpj-pipeline
            image: sua-imagem
          restartPolicy: OnFailure
```

**GitHub Actions:**
```yaml
on:
  schedule:
    - cron: '0 2 5 * *'  # Dia 5 √†s 2h UTC
```

### Plataformas que Requerem Containers Ativos

Algumas plataformas (PaaS) esperam que containers permane√ßam em execu√ß√£o. Se necess√°rio:

```bash
# Manter container ativo
docker run -d --name cnpj sua-imagem tail -f /dev/null

# Agendar execu√ß√£o mensal do comando:
docker exec cnpj python main.py
```

## Arquitetura

```
cnpj-data-pipeline/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Configura√ß√£o com auto-detec√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ downloader.py      # Download e extra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ processor.py       # Parsing e transforma√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ filters/           # Sistema de filtros
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py        # Interface de filtros
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ location.py    # Filtros geogr√°ficos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ business.py    # Filtros de neg√≥cio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ registry.py    # Factory de filtros
‚îÇ   ‚îú‚îÄ‚îÄ download_strategies/ # Estrat√©gias de download
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sequential.py  # Download sequencial
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ parallel.py    # Download paralelo
‚îÇ   ‚îî‚îÄ‚îÄ database/          # Abstra√ß√£o de banco de dados
‚îÇ       ‚îú‚îÄ‚îÄ base.py        # Interface abstrata
‚îÇ       ‚îú‚îÄ‚îÄ factory.py     # Factory pattern
‚îÇ       ‚îî‚îÄ‚îÄ postgres.py    # Implementa√ß√£o PostgreSQL
‚îú‚îÄ‚îÄ main.py                # Ponto de entrada
‚îî‚îÄ‚îÄ setup.py               # Assistente de configura√ß√£o
```

## Fluxo de Processamento

1. **Descoberta**: Localiza diret√≥rio mais recente de dados CNPJ
2. **Download**: Baixa e extrai arquivos ZIP com retry autom√°tico (paralelo opcional)
3. **Filtragem**: Aplica filtros selecionados para reduzir dados processados
4. **Processamento**: Parse dos CSVs com estrat√©gia adaptativa
5. **Carga**: Bulk upsert otimizado no banco de dados
6. **Rastreamento**: Marca arquivos como processados

## Tipos de Arquivo Suportados

| Arquivo | Tabela | Descri√ß√£o |
|---------|--------|-----------|
| `CNAECSV` | `cnaes` | Classifica√ß√µes de atividade econ√¥mica |
| `EMPRECSV` | `empresas` | Registros de empresas |
| `ESTABELECSV` | `estabelecimentos` | Dados de estabelecimentos |
| `MOTICSV` | `motivos_situacao_cadastral` | Motivos de situa√ß√£o cadastral |
| `MUNICCSV` | `municipios` | C√≥digos de munic√≠pios |
| `NATJUCSV` | `naturezas_juridicas` | Naturezas jur√≠dicas |
| `PAISCSV` | `paises` | C√≥digos de pa√≠ses |
| `QUALSCSV` | `qualificacoes_socios` | Qualifica√ß√µes de s√≥cios |
| `SIMPLECSV` | `dados_simples` | Dados do Simples Nacional |
| `SOCIOCSV` | `socios` | Quadro societ√°rio |

## Performance

Tempos t√≠picos de processamento:

| Sistema | Mem√≥ria | Tempo (63M+ empresas) |
|---------|---------|---------------------|
| VPS b√°sico | 4GB | ~8 horas |
| Servidor padr√£o | 16GB | ~2 horas |
| Servidor high-end | 64GB+ | ~1 hora |

## Desenvolvimento

### Princ√≠pios de Design

- **Modular**: Cada componente com responsabilidade √∫nica
- **Resiliente**: Tratamento de erros e retry autom√°tico
- **Eficiente**: Uso otimizado de mem√≥ria e opera√ß√µes bulk
- **Adaptativo**: Ajuste autom√°tico aos recursos dispon√≠veis

### Adicionando Novo Backend

1. Criar adapter em `src/database/seu_banco.py`
2. Implementar m√©todos abstratos de `DatabaseAdapter`
3. Registrar no factory em `src/database/factory.py`
4. Criar arquivo de requirements em `requirements/seu_banco.txt`

---

# üáßüá∑ CNPJ Data Pipeline (English)

A configurable, modular data pipeline for Brazilian CNPJ registry files. Smart processing of 60+ million companies with multi-database support.

## Key Features

- **Modular Architecture**: Clean separation with database abstraction
- **Multi-Database**: Full PostgreSQL support, placeholders for others
- **Smart Processing**: Auto-adapts to available resources
- **Advanced Filtering**: Filter by state, CNAE, and company size via CLI
- **Parallel Downloads**: Configurable strategy for optimized download speed
- **Incremental**: Tracks processed files
- **Optimized**: Efficient bulk operations
- **Easy Config**: Interactive setup + env vars

## Quick Start

### Interactive Setup

```bash
python setup.py
```

### Manual Setup

```bash
pip install -r requirements.txt
cp env.example .env
python main.py
```

### Docker

```bash
docker-compose --profile postgres up --build

# With data filtering
docker-compose run --rm pipeline --filter-uf SP --filter-cnae 62

# With parallel downloads
DOWNLOAD_STRATEGY=parallel DOWNLOAD_WORKERS=3 docker-compose up
```

## Data Filtering

Process only the data you need using command-line filters:

```bash
# Filter by state
python main.py --filter-uf SP,RJ

# Filter by economic activity (CNAE code prefix)
python main.py --filter-cnae 62,47

# Filter by company size (1=ME, 3=EPP, 5=Others)
python main.py --filter-porte 1,3

# Combine filters
python main.py --filter-uf SP --filter-cnae 62 --filter-porte 1

# List available filters
python main.py --list-filters
```

## Deployment

This is a batch job that processes CNPJ data and exits. Schedule it to run monthly.

### Manual Execution

```bash
# Run once
docker-compose up
```

### Scheduled Execution (Monthly)

**Linux/Mac (cron):**
```bash
# Run on the 5th of each month at 2 AM
0 2 5 * * cd /path/to/cnpj-pipeline && docker-compose up
```

**Other platforms:** Use your platform's scheduler (Task Scheduler, Kubernetes CronJob, GitHub Actions, etc.)

### Note for PaaS Platforms

If your platform requires containers to stay running:

```bash
# Keep container alive
docker run -d --name cnpj your-image tail -f /dev/null

# Schedule this command monthly:
docker exec cnpj python main.py
```

## Configuration

Set `DATABASE_BACKEND`, `PROCESSING_STRATEGY`, and optimization options in `.env` file:

```bash
# Performance optimizations
DOWNLOAD_STRATEGY=parallel    # sequential|parallel
DOWNLOAD_WORKERS=4           # Number of parallel downloads
KEEP_DOWNLOADED_FILES=false  # Keep files for re-runs (saves bandwidth)
```

## Architecture

Factory pattern for database adapters, intelligent resource detection, chunked processing for large files.

## Performance

Processes 63M+ records in 1-12 hours depending on system resources.

Made with engineering excellence for the Brazilian tech community.

## üìã Legalidade e Origem dos Dados

### ‚úÖ Dados 100% Legais e Oficiais

Estes dados s√£o **p√∫blicos e oficiais**, disponibilizados pela pr√≥pria Receita Federal atrav√©s do Portal de Dados Abertos do Governo Federal:

- **Fonte oficial**: [Portal de Dados Abertos](https://dados.gov.br/dados/conjuntos-dados/cadastro-nacional-da-pessoa-juridica---cnpj)
- **Base legal**: [Lei de Acesso √† Informa√ß√£o (Lei 12.527/2011)](https://www.planalto.gov.br/ccivil_03/_ato2011-2014/2011/lei/l12527.htm)
- **Atualiza√ß√£o**: Mensal pela Receita Federal

### ‚ö†Ô∏è O que N√ÉO s√£o estes dados:
- ‚ùå N√ÉO s√£o dados vazados ou obtidos ilegalmente
- ‚ùå N√ÉO cont√™m informa√ß√µes pessoais de pessoas f√≠sicas
- ‚ùå N√ÉO s√£o os "CDs de dados" vendidos ilegalmente
- ‚ùå N√ÉO violam LGPD ou privacidade

### üìå Uso Respons√°vel
Embora os dados sejam p√∫blicos, use-os com responsabilidade:
- ‚úÖ An√°lises de mercado e econ√¥micas
- ‚úÖ Pesquisa acad√™mica
- ‚úÖ Desenvolvimento de produtos B2B
- ‚úÖ Jornalismo de dados
- ‚ö†Ô∏è Sempre respeite limites √©ticos
- ‚ö†Ô∏è N√£o use para spam ou ass√©dio comercial
- üîí Respeite sempre a [LGPD](https://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/l13709.htm).

[![Dados Oficiais](https://img.shields.io/badge/Dados-Oficiais%20Receita%20Federal-green)](https://www.gov.br/receitafederal/pt-br/acesso-a-informacao/dados-abertos)
[![Lei de Acesso √† Informa√ß√£o](https://img.shields.io/badge/LAI-12.527%2F2011-blue)](http://www.planalto.gov.br/ccivil_03/_ato2011-2014/2011/lei/l12527.htm)
[![LGPD Compliant](https://img.shields.io/badge/LGPD-Compliant-brightgreen)](https://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/l13709.htm)


=======
Made with ‚ù§Ô∏è for the Brazilian tech community
